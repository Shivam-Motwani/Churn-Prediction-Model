{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b93198",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of customer churn prediction using the Telco Customer Churn dataset.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Overview](#1-data-loading-and-overview)\n",
    "2. [Exploratory Data Analysis](#2-exploratory-data-analysis)\n",
    "3. [Data Preprocessing](#3-data-preprocessing)\n",
    "4. [Feature Engineering](#4-feature-engineering)\n",
    "5. [Model Training and Evaluation](#5-model-training-and-evaluation)\n",
    "6. [Feature Importance Analysis](#6-feature-importance-analysis)\n",
    "7. [Model Comparison](#7-model-comparison)\n",
    "8. [Conclusions and Recommendations](#8-conclusions-and-recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9931ee3",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ae71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb368ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: Download the Telco Customer Churn dataset from Kaggle\n",
    "# https://www.kaggle.com/blastchar/telco-customer-churn\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please download the Telco Customer Churn dataset.\")\n",
    "    print(\"URL: https://www.kaggle.com/blastchar/telco-customer-churn\")\n",
    "    # Create sample data for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'customerID': range(1000),\n",
    "        'gender': np.random.choice(['Male', 'Female'], 1000),\n",
    "        'SeniorCitizen': np.random.choice([0, 1], 1000),\n",
    "        'tenure': np.random.randint(1, 72, 1000),\n",
    "        'MonthlyCharges': np.random.uniform(18, 118, 1000),\n",
    "        'TotalCharges': np.random.uniform(18, 8000, 1000),\n",
    "        'Churn': np.random.choice(['Yes', 'No'], 1000, p=[0.27, 0.73])\n",
    "    })\n",
    "    print(\"Using sample data for demonstration.\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17631fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b08c0",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Count plot\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "axes[0].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Churn Distribution')\n",
    "\n",
    "# Bar plot\n",
    "sns.countplot(data=df, x='Churn', ax=axes[1])\n",
    "axes[1].set_title('Churn Count')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Churn Rate: {(df['Churn'] == 'Yes').mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('customerID')  # Remove ID column\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')  # Remove target variable\n",
    "\n",
    "# Create subplots for categorical features\n",
    "n_cols = 3\n",
    "n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "\n",
    "for i, col in enumerate(categorical_cols[:len(axes)]):\n",
    "    if i < len(categorical_cols):\n",
    "        churn_by_category = pd.crosstab(df[col], df['Churn'], normalize='index') * 100\n",
    "        churn_by_category.plot(kind='bar', ax=axes[i], rot=45)\n",
    "        axes[i].set_title(f'Churn Rate by {col}')\n",
    "        axes[i].set_ylabel('Percentage')\n",
    "        axes[i].legend(title='Churn')\n",
    "    else:\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e562bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numerical features\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_cols[:4]):\n",
    "    df.boxplot(column=col, by='Churn', ax=axes[i])\n",
    "    axes[i].set_title(f'{col} by Churn Status')\n",
    "    axes[i].set_xlabel('Churn')\n",
    "\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Convert categorical variables to numerical for correlation\n",
    "df_encoded = df.copy()\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df_encoded.select_dtypes(include=['object']).columns:\n",
    "    if col != 'customerID':\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_encoded.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123c702",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove customerID as it's not useful for prediction\n",
    "if 'customerID' in df_clean.columns:\n",
    "    df_clean = df_clean.drop('customerID', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Convert TotalCharges to numeric (it might be stored as string)\n",
    "if 'TotalCharges' in df_clean.columns:\n",
    "    df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "    \n",
    "    # Fill missing TotalCharges with median\n",
    "    df_clean['TotalCharges'].fillna(df_clean['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(f\"\\nDataset shape after cleaning: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_processed = df_clean.copy()\n",
    "\n",
    "# Binary encoding for Yes/No columns\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "for col in binary_cols:\n",
    "    if col in df_processed.columns:\n",
    "        df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Label encoding for other categorical columns\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('Churn')  # Keep target variable for later\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "target_encoder = LabelEncoder()\n",
    "df_processed['Churn'] = target_encoder.fit_transform(df_processed['Churn'])\n",
    "\n",
    "print(\"Categorical encoding completed!\")\n",
    "print(f\"\\nProcessed dataset shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360d768",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df_features = df_processed.copy()\n",
    "\n",
    "# Create new features\n",
    "if 'tenure' in df_features.columns and 'MonthlyCharges' in df_features.columns:\n",
    "    # Average monthly charges per tenure\n",
    "    df_features['AvgChargesPerTenure'] = df_features['MonthlyCharges'] / (df_features['tenure'] + 1)\n",
    "    \n",
    "    # Tenure groups\n",
    "    df_features['TenureGroup'] = pd.cut(df_features['tenure'], \n",
    "                                       bins=[0, 12, 24, 48, 72], \n",
    "                                       labels=['0-1 year', '1-2 years', '2-4 years', '4+ years'])\n",
    "    df_features['TenureGroup'] = df_features['TenureGroup'].cat.codes\n",
    "\n",
    "if 'MonthlyCharges' in df_features.columns:\n",
    "    # Monthly charges groups\n",
    "    df_features['ChargesGroup'] = pd.cut(df_features['MonthlyCharges'], \n",
    "                                        bins=[0, 35, 65, 95, 200], \n",
    "                                        labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    df_features['ChargesGroup'] = df_features['ChargesGroup'].cat.codes\n",
    "\n",
    "if 'TotalCharges' in df_features.columns and 'MonthlyCharges' in df_features.columns:\n",
    "    # Ratio of total to monthly charges\n",
    "    df_features['TotalToMonthlyRatio'] = df_features['TotalCharges'] / df_features['MonthlyCharges']\n",
    "\n",
    "# Service count (count of additional services)\n",
    "service_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "existing_service_cols = [col for col in service_cols if col in df_features.columns]\n",
    "if existing_service_cols:\n",
    "    df_features['ServiceCount'] = df_features[existing_service_cols].sum(axis=1)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New dataset shape: {df_features.shape}\")\n",
    "print(f\"New features created: {set(df_features.columns) - set(df_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b77708",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = df_features.drop('Churn', axis=1)\n",
    "y = df_features['Churn']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test_scaled[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Target distribution in training set: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Use scaled data for Logistic Regression, original for tree-based models\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    if name == 'Logistic Regression':\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'auc_score': auc_score,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"AUC Score: {auc_score:.4f}\")\n",
    "    print(f\"CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, results in model_results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, results['probabilities'])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {results['auc_score']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd0929",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['auc_score'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "print(f\"Best AUC Score: {model_results[best_model_name]['auc_score']:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance = best_model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "    plt.title(f'Top 15 Feature Importances - {best_model_name}')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # For logistic regression\n",
    "    coef = np.abs(best_model.coef_[0])\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': coef\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "    plt.title(f'Top 15 Feature Coefficients (Absolute) - {best_model_name}')\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for model interpretability\n",
    "try:\n",
    "    if best_model_name in ['Random Forest', 'XGBoost', 'LightGBM']:\n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "        shap_values = explainer.shap_values(X_test.iloc[:100])  # Use first 100 samples for speed\n",
    "        \n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1]  # For binary classification, take positive class\n",
    "        \n",
    "        # Summary plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_test.iloc[:100], show=False)\n",
    "        plt.title(f'SHAP Summary Plot - {best_model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Feature importance plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        shap.summary_plot(shap_values, X_test.iloc[:100], plot_type=\"bar\", show=False)\n",
    "        plt.title(f'SHAP Feature Importance - {best_model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"SHAP analysis failed: {e}\")\n",
    "    print(\"Continuing without SHAP analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a18e9",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison summary\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(model_results.keys()),\n",
    "    'AUC Score': [results['auc_score'] for results in model_results.values()],\n",
    "    'CV Mean': [results['cv_mean'] for results in model_results.values()],\n",
    "    'CV Std': [results['cv_std'] for results in model_results.values()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('AUC Score', ascending=False)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# AUC Score comparison\n",
    "sns.barplot(data=comparison_df, x='AUC Score', y='Model', ax=axes[0])\n",
    "axes[0].set_title('Model AUC Score Comparison')\n",
    "axes[0].set_xlim(0, 1)\n",
    "\n",
    "# CV Score comparison with error bars\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['CV Mean'], \n",
    "             xerr=comparison_df['CV Std'], capsize=5)\n",
    "axes[1].set_title('Cross-Validation Score Comparison')\n",
    "axes[1].set_xlabel('CV Mean Score')\n",
    "axes[1].set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, results) in enumerate(model_results.items()):\n",
    "    cm = confusion_matrix(y_test, results['predictions'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'Confusion Matrix - {name}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931054f2",
   "metadata": {},
   "source": [
    "## 8. Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237faadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights and recommendations\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOMER CHURN PREDICTION ANALYSIS - CONCLUSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. BEST PERFORMING MODEL:\")\n",
    "print(f\"   - Model: {best_model_name}\")\n",
    "print(f\"   - AUC Score: {model_results[best_model_name]['auc_score']:.4f}\")\n",
    "print(f\"   - Cross-validation: {model_results[best_model_name]['cv_mean']:.4f} (+/- {model_results[best_model_name]['cv_std']:.4f})\")\n",
    "\n",
    "print(f\"\\n2. DATASET INSIGHTS:\")\n",
    "print(f\"   - Total customers analyzed: {len(df)}\")\n",
    "print(f\"   - Overall churn rate: {(df['Churn'] == 'Yes').mean():.2%}\")\n",
    "print(f\"   - Features analyzed: {len(X.columns)}\")\n",
    "\n",
    "if 'importance_df' in locals():\n",
    "    print(f\"\\n3. KEY CHURN INDICATORS:\")\n",
    "    for i, row in importance_df.head(5).iterrows():\n",
    "        print(f\"   - {row['feature'].replace('_', ' ').title()}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n4. BUSINESS RECOMMENDATIONS:\")\n",
    "print(f\"   - Focus retention efforts on high-risk customers identified by the model\")\n",
    "print(f\"   - Implement proactive customer engagement strategies\")\n",
    "print(f\"   - Monitor key indicators like tenure, contract type, and monthly charges\")\n",
    "print(f\"   - Consider offering incentives for longer-term contracts\")\n",
    "print(f\"   - Improve customer service for high-value, at-risk customers\")\n",
    "\n",
    "print(f\"\\n5. MODEL DEPLOYMENT:\")\n",
    "print(f\"   - The {best_model_name} model is ready for production deployment\")\n",
    "print(f\"   - Implement regular model retraining with new data\")\n",
    "print(f\"   - Set up monitoring for model performance drift\")\n",
    "print(f\"   - Create automated alerts for high-risk customers\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and preprocessing objects\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, f'../models/best_churn_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(label_encoders, '../models/label_encoders.pkl')\n",
    "joblib.dump(target_encoder, '../models/target_encoder.pkl')\n",
    "\n",
    "# Save feature names\n",
    "feature_names = list(X.columns)\n",
    "joblib.dump(feature_names, '../models/feature_names.pkl')\n",
    "\n",
    "print(f\"Model artifacts saved successfully!\")\n",
    "print(f\"- Best model: ../models/best_churn_model_{best_model_name.lower().replace(' ', '_')}.pkl\")\n",
    "print(f\"- Scaler: ../models/scaler.pkl\")\n",
    "print(f\"- Label encoders: ../models/label_encoders.pkl\")\n",
    "print(f\"- Target encoder: ../models/target_encoder.pkl\")\n",
    "print(f\"- Feature names: ../models/feature_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03375922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample prediction function\n",
    "def predict_churn(customer_data, model=best_model, scaler=scaler, \n",
    "                  label_encoders=label_encoders, feature_names=feature_names):\n",
    "    \"\"\"\n",
    "    Predict churn probability for a single customer\n",
    "    \n",
    "    Args:\n",
    "        customer_data (dict): Customer features\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    # Create DataFrame from input\n",
    "    df_input = pd.DataFrame([customer_data])\n",
    "    \n",
    "    # Apply same preprocessing\n",
    "    # (This is a simplified version - in production, use the preprocessing pipeline)\n",
    "    \n",
    "    # Make prediction\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        prediction_proba = model.predict_proba(df_input)[:, 1][0]\n",
    "    else:\n",
    "        prediction_proba = model.predict_proba(df_input)[:, 1][0]\n",
    "    \n",
    "    prediction = 1 if prediction_proba > 0.5 else 0\n",
    "    \n",
    "    return {\n",
    "        'churn_probability': prediction_proba,\n",
    "        'churn_prediction': prediction,\n",
    "        'risk_level': 'High' if prediction_proba > 0.7 else 'Medium' if prediction_proba > 0.3 else 'Low'\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "sample_customer = {\n",
    "    'tenure': 12,\n",
    "    'MonthlyCharges': 75.0,\n",
    "    'TotalCharges': 900.0\n",
    "    # Add other features as needed\n",
    "}\n",
    "\n",
    "print(\"\\nSample Prediction:\")\n",
    "print(\"Customer data:\", sample_customer)\n",
    "# result = predict_churn(sample_customer)\n",
    "# print(\"Prediction result:\", result)\n",
    "print(\"(Note: Full prediction function requires complete preprocessing pipeline)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
